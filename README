# ğŸ© Pastry Object Detection using YOLOv11  

## ğŸ“Œ Project Overview  
This project focuses on **object detection** applied to pastry products, including **pain au chocolat, Ã©clair, muffin, donut, and tart**. The goal is to fine-tune **YOLOv11**, a state-of-the-art object detection model, to accurately detect and classify these pastries within images.  

We collected and annotated a **small dataset (100 images)**, conducted multiple training experiments with different hyperparameter configurations, and evaluated the modelâ€™s performance using quantitative and qualitative metrics.  

---

## ğŸš€ Features  
- âœ… **Fine-tuned YOLOv11 model** for pastry detection.  
- âœ… **Custom dataset** with annotated images.  
- âœ… **Data augmentation** using **Albumentations** to enhance generalization.  
- âœ… **Hyperparameter optimization** through multiple training attempts.  
- âœ… **Evaluation and visualization** of model performance on test images.  

---

## ğŸ“‚ Dataset Structure  
The dataset consists of **100 images**, split as follows:  

- **Training set**: 70 images  
- **Validation set**: 20 images  
- **Test set**: 10 images  

Each image is labeled with bounding boxes and stored in YOLO format. The dataset includes five classes:  

1. **Pain au chocolat**  
2. **Ã‰clair**  
3. **Muffin**  
4. **Donut**  
5. **Tart**  

---

## âš™ï¸ Installation  

### 1ï¸âƒ£ Clone the repository  
```bash
git clone https://github.com/yourusername/pastry-detection-yolov11.git
cd pastry-detection-yolov11
```

### 2ï¸âƒ£ Install dependencies  
```bash
pip install ultralytics albumentations opencv-python matplotlib
```

---

## ğŸ‹ï¸â€â™‚ï¸ Model Training  

To train the YOLOv11 model, run the following command:  
```python
from ultralytics import YOLO

# Load the pretrained YOLOv11 model
model = YOLO("yolo11n.pt")

# Train the model
model.train(data="dataset_yolov11/data.yaml", epochs=50, imgsz=640, batch=16, patience=10, lr0=0.01, lrf=0.0001)
```

---

## ğŸ“Š Evaluation  

Once the model is trained, evaluate its performance using:  
```python
# Load best model
best_model = YOLO("runs/detect/train/weights/best.pt")

# Validate the model
metrics = best_model.val()
print(f"mAP50-95: {metrics.box.map}")
```

### **Results Analysis**
- ğŸ“Œ **Confusion matrix** shows correct and incorrect classifications.  
- ğŸ“Œ **F1-score curve** helps determine the optimal confidence threshold.  
- ğŸ“Œ **Visual predictions** on test images to assess model accuracy.  

---

## ğŸ¯ Predictions on Test Images  

Run the model on new images:  
```python
from PIL import Image

# Load test image
test_image = Image.open("dataset_yolov11/test/images/sample.jpg")

# Predict
results = best_model.predict(source=test_image, save=True)
```

The predictions are stored in the `runs/detect/predict/` directory.

---

## ğŸ“ Repository Structure  

```
ğŸ“‚ pastry-detection-yolov11
 â”œâ”€â”€ ğŸ“‚ dataset_yolov11         # Dataset (train, val, test images + annotations)
 â”œâ”€â”€ ğŸ“‚ runs                    # Training logs and model checkpoints
 â”œâ”€â”€ ğŸ“‚ notebooks                # Jupyter notebooks for training and evaluation
 â”œâ”€â”€ ğŸ“‚ results                  # Evaluation metrics and predictions
 â”œâ”€â”€ train_model.py              # YOLOv11 training script
 â”œâ”€â”€ evaluate_model.py           # Model evaluation script
 â”œâ”€â”€ README.md                   # Project documentation
 â”œâ”€â”€ requirements.txt            # List of dependencies
```

---


## ğŸ“œ License  
This project is open-source and available under the **MIT License**.  

---

## ğŸ‘¤ Author  
**Akrem JOMAA**  
ğŸ“§ Contact: [akrem.jomaa@univ-lyon2.fr](mailto:akrem.jomaa@univ-lyon2.fr)  
ğŸ”— LinkedIn: [akremjomaa](www.linkedin.com/in/akremjomaa)  
ğŸ“‚ GitHub: [github.com/akremjomaa](https://github.com/akremjomaa)  

---

ğŸš€ **If you find this project useful, don't forget to star â­ the repository!**  
